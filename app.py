from flask import (
    Flask,
    render_template,
    request,
    redirect,
    url_for,
    session,
    flash,
    jsonify,
)
from openai import OpenAI
from dotenv import load_dotenv
import sqlite3, os, hashlib, json, requests
from bs4 import BeautifulSoup
import re
import time
import secrets
from urllib.parse import quote
from datetime import datetime, timedelta
from collections import Counter

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
# å»ºç«‹ä¸€å€‹ OpenAI å®¢æˆ¶ç«¯å¯¦ä¾‹
client = OpenAI(api_key=api_key)
app = Flask(__name__)
app.secret_key = secrets.token_hex(32)
DB_NAME = "users.db"


# å¯†ç¢¼ hash
def hash_password(password):
    return hashlib.sha256(password.encode()).hexdigest()


# è³‡æ–™åº«åˆå§‹åŒ–
def init_db():
    if not os.path.exists(DB_NAME):
        conn = sqlite3.connect(DB_NAME)
        c = conn.cursor()
        c.execute(
            """CREATE TABLE users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT UNIQUE NOT NULL,
                password TEXT NOT NULL
            )"""
        )
        c.execute(
            """CREATE TABLE conversations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT NOT NULL,
                user_message TEXT NOT NULL,
                bot_reply TEXT NOT NULL,
                learning_unit TEXT,
                scaffolding_type TEXT,
                understanding_level TEXT,
                analysis_reason TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )"""
        )

        # æ·»åŠ é è¨­çš„teacherå¸³è™Ÿ
        teacher_password = hash_password("teacher")  # å¯†ç¢¼ä¹Ÿæ˜¯teacher
        c.execute(
            "INSERT INTO users (username, password) VALUES (?, ?)",
            ("teacher", teacher_password),
        )

        conn.commit()
        conn.close()
        print("è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆï¼Œå·²å‰µå»ºteacherå¸³è™Ÿ")
    else:
        # æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°è³‡æ–™åº«çµæ§‹
        conn = sqlite3.connect(DB_NAME)
        c = conn.cursor()

        # æª¢æŸ¥teacherå¸³è™Ÿæ˜¯å¦å­˜åœ¨
        c.execute("SELECT * FROM users WHERE username = 'teacher'")
        teacher_exists = c.fetchone()

        if not teacher_exists:
            teacher_password = hash_password("teacher")
            c.execute(
                "INSERT INTO users (username, password) VALUES (?, ?)",
                ("teacher", teacher_password),
            )
            print("å·²æ·»åŠ teacherå¸³è™Ÿ")

        # æª¢æŸ¥æ˜¯å¦æœ‰æ–°çš„æ¬„ä½
        c.execute("PRAGMA table_info(conversations)")
        columns = [column[1] for column in c.fetchall()]

        new_columns = [
            ("learning_unit", "TEXT"),
            ("scaffolding_type", "TEXT"),
            ("understanding_level", "TEXT"),
            ("analysis_reason", "TEXT"),
        ]

        for col_name, col_type in new_columns:
            if col_name not in columns:
                c.execute(f"ALTER TABLE conversations ADD COLUMN {col_name} {col_type}")
                print(f"å·²æ–°å¢æ¬„ä½: {col_name}")

        conn.commit()
        conn.close()


###########################################################################  => home
# ç™»å…¥è¨»å†Šç•«é¢
@app.route("/")
def home():
    return render_template("home.html")


# ç™»å…¥API
@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        username = request.form["username"]
        password = hash_password(request.form["password"])

        conn = sqlite3.connect(DB_NAME)
        c = conn.cursor()
        c.execute(
            "SELECT * FROM users WHERE username = ? AND password = ?",
            (username, password),
        )
        user = c.fetchone()
        conn.close()

        if user:
            session["username"] = username
            # å¦‚æœæ˜¯æ•™å¸«å¸³è™Ÿï¼Œå°å‘æ•™å¸«åˆ†æé é¢
            if username == "teacher":
                return redirect(url_for("teacher_dashboard"))
            else:
                return redirect(url_for("video"))
        else:
            flash("å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤", "alert alert-danger")
            return redirect(url_for("home"))

    return redirect(url_for("home"))


# è¨»å†ŠAPI
@app.route("/register", methods=["GET", "POST"])
def register():
    if request.method == "POST":
        username = request.form["username"]
        password = hash_password(request.form["password"])
        try:
            conn = sqlite3.connect(DB_NAME)
            c = conn.cursor()
            c.execute(
                "INSERT INTO users (username, password) VALUES (?, ?)",
                (username, password),
            )
            conn.commit()
            conn.close()
            flash("è¨»å†ŠæˆåŠŸï¼Œè«‹ç™»å…¥ï¼", "alert alert-success")
            return render_template("home.html")
        except sqlite3.IntegrityError:
            flash("ä½¿ç”¨è€…åç¨±å·²å­˜åœ¨", "alert alert-danger")
    return render_template("home.html")


###########################################################################


###########################################################################  => video
# å½±ç‰‡å€
@app.route("/video")
def video():
    if "username" not in session:
        return redirect(url_for("home"))
    return render_template("video.html", username=session["username"])


# ç™»å‡ºæŒ‰éˆ•
@app.route("/logout")
def logout():
    session.pop("username", None)
    flash("å·²ç™»å‡º", "alert alert-success")
    return render_template("home.html")


# é·¹æ¶ç†è«–
LEARNING_UNITS = {
    "è³‡æ–™é è™•ç†": {
        "keywords": [
            "è³‡æ–™æ¸…æ´—",
            "ç¼ºå¤±å€¼",
            "ç•°å¸¸å€¼",
            "æ¨™æº–åŒ–",
            "æ­£è¦åŒ–",
            "ç‰¹å¾µé¸æ“‡",
            "è³‡æ–™è½‰æ›",
            "è³‡æ–™é è™•ç†",
            "è‡ªè®Šé‡",
            "æ‡‰è®Šé‡",
            "è³‡æ–™éºæ¼å€¼",
            "åˆ‡åˆ†",
        ],
        "difficulty_level": "åŸºç¤",
        "prerequisites": [],
    },
    "ç·šæ€§å›æ­¸": {
        "keywords": [
            "å›æ­¸åˆ†æ",
            "æœ€å°å¹³æ–¹æ³•",
            "ç›¸é—œä¿‚æ•¸",
            "é æ¸¬",
            "ç·šæ€§é—œä¿‚",
            "æ–œç‡",
            "æˆªè·",
            "è³‡æ–™é›†",
        ],
        "difficulty_level": "åŸºç¤",
        "prerequisites": ["è³‡æ–™é è™•ç†"],
    },
    "å¤šå…ƒç·šæ€§å›æ­¸": {
        "keywords": [
            "å¤šè®Šæ•¸",
            "å¤šå…ƒå›æ­¸",
            "è®Šæ•¸é¸æ“‡",
            "å…±ç·šæ€§",
            "èª¿æ•´Rå¹³æ–¹",
            "è™›æ“¬è®Šé‡",
        ],
        "difficulty_level": "ä¸­ç­‰",
        "prerequisites": ["ç·šæ€§å›æ­¸"],
    },
    "å¤šé …å¼å›æ­¸": {
        "keywords": ["éç·šæ€§", "å¤šé …å¼", "æ›²ç·šæ“¬åˆ", "éåº¦æ“¬åˆ", "è¤‡é›œåº¦", "degree"],
        "difficulty_level": "ä¸­ç­‰",
        "prerequisites": ["ç·šæ€§å›æ­¸"],
    },
    "æ”¯æ´å‘é‡æ©Ÿ": {
        "keywords": ["SVM", "æ ¸å‡½æ•¸", "æ”¯æ´å‘é‡", "åˆ†é¡", "æ±ºç­–é‚Šç•Œ", "margin"],
        "difficulty_level": "é€²éš",
        "prerequisites": ["ç·šæ€§å›æ­¸", "åˆ†é¡æ¦‚å¿µ"],
    },
    "è²æ°åˆ†é¡": {
        "keywords": ["è²æ°å®šç†", "æ¢ä»¶æ©Ÿç‡", "Naive Bayes", "ç‰¹å¾µç¨ç«‹æ€§"],
        "difficulty_level": "ä¸­ç­‰",
        "prerequisites": ["æ©Ÿç‡çµ±è¨ˆ"],
    },
    "æ±ºç­–æ¨¹": {
        "keywords": ["æ¨¹ç‹€çµæ§‹", "è³‡è¨Šå¢ç›Š", "ç†µ", "åˆ†æ”¯", "è‘‰ç¯€é»", "å‰ªæ"],
        "difficulty_level": "ä¸­ç­‰",
        "prerequisites": ["åˆ†é¡æ¦‚å¿µ"],
    },
    "éš¨æ©Ÿæ£®æ—": {
        "keywords": ["ensemble", "æ±ºç­–æ¨¹é›†åˆ", "éš¨æ©ŸæŠ½æ¨£", "æŠ•ç¥¨æ©Ÿåˆ¶", "ç‰¹å¾µéš¨æ©Ÿæ€§"],
        "difficulty_level": "é€²éš",
        "prerequisites": ["æ±ºç­–æ¨¹"],
    },
    "Kå¹³å‡åˆ†ç¾¤": {
        "keywords": ["åˆ†ç¾¤", "ç„¡ç›£ç£å­¸ç¿’", "ä¸­å¿ƒé»", "è·é›¢", "æ”¶æ–‚", "ç¾¤é›†"],
        "difficulty_level": "ä¸­ç­‰",
        "prerequisites": ["è³‡æ–™é è™•ç†"],
    },
    "äº¤å‰é©—è­‰": {
        "keywords": ["é©—è­‰", "éåº¦æ“¬åˆ", "æ¨¡å‹è©•ä¼°", "K-fold", "æ³›åŒ–èƒ½åŠ›"],
        "difficulty_level": "ä¸­ç­‰",
        "prerequisites": ["æ¨¡å‹è©•ä¼°æ¦‚å¿µ"],
    },
    "ç¶²æ ¼æœå°‹": {
        "keywords": ["è¶…åƒæ•¸èª¿æ•´", "åƒæ•¸æœ€ä½³åŒ–", "æ¨¡å‹èª¿æ ¡", "Grid Search"],
        "difficulty_level": "é€²éš",
        "prerequisites": ["äº¤å‰é©—è­‰", "æ¨¡å‹è©•ä¼°"],
    },
    "SVM": {
        "keywords": ["æ”¯æŒå‘é‡æ©Ÿ", "åˆ†é¡å™¨", "è¶…å¹³é¢", "Support Vector Machine"],
        "difficulty_level": "é€²éš",
        "prerequisites": ["è³‡æ–™é è™•ç†", "ç·šæ€§å›æ­¸"],
    },
    "é‚è¼¯å›æ­¸": {
        "keywords": ["Logistic Regression", "äºŒå…ƒåˆ†é¡", "æ©Ÿç‡æ¨¡å‹", "Sigmoid å‡½æ•¸"],
        "difficulty_level": "ä¸­éš",
        "prerequisites": ["ç›£ç£å¼å­¸ç¿’", "ç·šæ€§å›æ­¸", "æ©Ÿç‡èˆ‡çµ±è¨ˆ"],
    },
}


# å¾å°è©±å»çŒœï¼Œä½¿ç”¨è€…æœ‰å•é¡Œçš„å–®å…ƒ
def identify_learning_unit(user_message):
    """è­˜åˆ¥ä½¿ç”¨è€…è¨Šæ¯ä¸­çš„å­¸ç¿’å–®å…ƒ"""
    message_lower = user_message.lower()

    for unit, info in LEARNING_UNITS.items():
        # æª¢æŸ¥å–®å…ƒåç¨±
        if unit.lower() in message_lower:
            return unit

        # æª¢æŸ¥é—œéµè©
        for keyword in info["keywords"]:
            if keyword.lower() in message_lower:
                return unit

    return "é€šç”¨æ¦‚å¿µ"  # é è¨­å–®å…ƒ


# å„²å­˜èŠå¤©è³‡æ–™ - åŠ å…¥é·¹æ¶ç†è«–åˆ†æAPI
@app.route("/chat", methods=["POST"])
def chat():
    if "username" not in session:
        return jsonify({"error": "æœªç™»å…¥"}), 401

    username = session["username"]
    user_message = request.json.get("message")

    try:
        learning_unit = identify_learning_unit(user_message)
        user_history = get_user_learning_history(username)

        scaffolding_type, understanding_level, analysis_reason = (
            analyze_scaffolding_need(
                user_message, learning_unit, user_history, username
            )
        )

        # å†æ¬¡ç¢ºä¿æ­£ç¢ºæ ¼å¼
        scaffolding_type = normalize_scaffolding_type(scaffolding_type)

        reply = generate_scaffolded_response(
            user_message, learning_unit, scaffolding_type, understanding_level
        )

        conn = sqlite3.connect(DB_NAME)
        c = conn.cursor()
        c.execute(
            """
            INSERT INTO conversations 
            (username, user_message, bot_reply, learning_unit, scaffolding_type, understanding_level, analysis_reason) 
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """,
            (
                username,
                user_message,
                reply,
                learning_unit,
                scaffolding_type,
                understanding_level,
                analysis_reason,
            ),
        )
        conn.commit()
        conn.close()

        return jsonify(
            {
                "reply": reply,
                "learning_unit": learning_unit,
                "scaffolding_type": scaffolding_type,
                "understanding_level": understanding_level,
                "analysis_reason": analysis_reason,
            }
        )

    except Exception as e:
        return jsonify({"error": str(e)}), 500


# çµ¦å‡ºå°æ‡‰çš„é·¹æ¶å›æ‡‰
def _postprocess_complete_sentences(text):
    """ç¢ºä¿å›è¦†ä¸ä»¥åŠå¥æ”¶å°¾ï¼šæˆªåˆ°æœ€å¾Œå®Œæ•´å¥ï¼Œè‹¥æ²’æœ‰å‰‡è£œä¸Šå¥è™Ÿã€‚"""
    if not text:
        return text
    text = text.replace("[[END]]", "").strip()
    if re.search(r"[ã€‚\.!?ï¼\?]$", text):
        return text
    m = re.search(r"(.+[ã€‚\.!?ï¼\?])", text)
    if m:
        return m.group(1).strip()
    return text + "ã€‚"


def format_code_blocks(text):
    # å°‡ ```python ... ``` è½‰æˆ <pre><code class="language-python">...</code></pre>
    return re.sub(
        r"```python(.*?)```",
        r'<pre><code class="language-python">\1</code></pre>',
        text,
        flags=re.DOTALL,
    )


def generate_scaffolded_response(
    user_message, learning_unit, scaffolding_type, understanding_level
):
    """æ ¹æ“šé·¹æ¶é¡å‹ç”¢ç”Ÿèšç„¦ä¸”å¯åŒ…å«ç¨‹å¼ç¯„ä¾‹çš„å›è¦†"""

    # ç¢ºä¿é·¹æ¶é¡å‹æ­£ç¢º
    scaffolding_type = normalize_scaffolding_type(scaffolding_type)

    level_hint = {
        "åˆå­¸è€…": "è«‹ä½¿ç”¨æ·ºé¡¯èªè¨€èˆ‡ç”Ÿæ´»åŒ–æ¯”å–»ã€‚",
        "é€²éšå­¸ç¿’è€…": "å¯ä½¿ç”¨éƒ¨åˆ†å°ˆæ¥­è©å½™èˆ‡ç°¡çŸ­ç¨‹å¼ç¯„ä¾‹ã€‚",
        "ç†Ÿç·´è€…": "è«‹æä¾›æŠ€è¡“ç´°ç¯€ã€æ•ˆç‡æ¯”è¼ƒæˆ–å»¶ä¼¸æ‡‰ç”¨ã€‚",
    }.get(understanding_level, "")

    code_hint = "å¦‚æœå­¸ç”Ÿçš„å•é¡Œæ¶‰åŠå¯¦ä½œæˆ–èªæ³•ï¼Œè«‹é™„ä¸Šä¸€æ®µç°¡çŸ­çš„ Python ç¨‹å¼ç¢¼å€å¡Šï¼Œç¨‹å¼ç¢¼é•·åº¦ä¸è¶…é15è¡Œã€‚"

    scaffolding_prompts = {
        "å·®ç•°é·¹æ¶": f"""
ä½ æ˜¯ä¸€ä½æ©Ÿå™¨å­¸ç¿’å°å¸«ï¼Œæ­£åœ¨ä½¿ç”¨ã€Œå·®ç•°é·¹æ¶ã€ç­–ç•¥ï¼Œ
ç›®çš„æ˜¯æ ¹æ“šå­¸ç”Ÿçš„ç†è§£ç¨‹åº¦èˆ‡å­¸ç¿’é¢¨æ ¼çµ¦äºˆé©æ€§åŒ–å¼•å°ã€‚

æ•™å­¸åŸå‰‡ï¼š
- å¾åŸºç¤æ¦‚å¿µé–‹å§‹ï¼Œèªªæ˜ç°¡å–®æ¸…æ¥š
- ä½¿ç”¨ç”Ÿæ´»åŒ–æ¯”å–»å¹«åŠ©å­¸ç”Ÿé€£çµç¶“é©—
- è‹¥å­¸ç”Ÿæåˆ°ç¨‹å¼ç›¸é—œå•é¡Œï¼Œå¯æä¾›ç¯„ä¾‹ç¨‹å¼ç¢¼
- çµå°¾é¼“å‹µå­¸ç”Ÿåæ€æˆ–å†æå•

è«‹ç”¨ 3â€“4 å¥è‡ªç„¶èªæ°£å›ç­”ï¼Œæ¯å¥ä¸è¶…é 25 å­—ã€‚
{level_hint}
{code_hint}
ä¸»é¡Œï¼š{learning_unit}
å­¸ç”Ÿæå•ï¼š{user_message}
å›ç­”çµæŸæ™‚è¼¸å‡º [[END]]
""",
        "é‡è¤‡é·¹æ¶": f"""
ä½ æ˜¯ä¸€ä½æ©Ÿå™¨å­¸ç¿’å°å¸«ï¼Œæ­£åœ¨ä½¿ç”¨ã€Œé‡è¤‡é·¹æ¶ã€ç­–ç•¥ï¼Œ
å¹«åŠ©å­¸ç”Ÿé€éå¤šç¨®èªªæ˜æ–¹å¼éå›ºåŒä¸€æ¦‚å¿µã€‚

æ•™å­¸åŸå‰‡ï¼š
- ç”¨ä¸åŒä¾‹å­èˆ‡èªå¢ƒé‡è¿°æ ¸å¿ƒæ¦‚å¿µ
- å¯æä¾›å°ç…§å¼ç¨‹å¼ç¢¼ç¯„ä¾‹
- é¼“å‹µå­¸ç”Ÿè‡ªå·±è©¦è‘—å¯«å‡ºé¡ä¼¼ç¨‹å¼
- çµå°¾é™„ä¸Šã€Œç·´ç¿’æ–¹å‘ã€

è«‹ç”¨ 3â€“4 å¥å›ç­”ï¼Œæ¯å¥ä¸è¶…é 25 å­—ã€‚
{level_hint}
{code_hint}
ä¸»é¡Œï¼š{learning_unit}
å­¸ç”Ÿæå•ï¼š{user_message}
å›ç­”çµæŸæ™‚è¼¸å‡º [[END]]
""",
        "å”åŒé·¹æ¶": f"""
ä½ æ˜¯ä¸€ä½æ©Ÿå™¨å­¸ç¿’å°ˆå®¶ï¼Œæ­£åœ¨ä½¿ç”¨ã€Œå”åŒé·¹æ¶ã€ç­–ç•¥ï¼Œ
å”åŠ©å­¸ç”Ÿæ•´åˆè·¨é ˜åŸŸçŸ¥è­˜ä¸¦é€²è¡Œé«˜å±¤æ¬¡æ€è€ƒã€‚

æ•™å­¸åŸå‰‡ï¼š
- å…ˆé»å‡ºæ ¸å¿ƒé‚è¼¯æˆ–ç†è«–é—œè¯
- å†æå‡ºå»¶ä¼¸æ‡‰ç”¨æˆ–æŒ‘æˆ°å•é¡Œ
- è‹¥ç›¸é—œï¼Œå¯é™„ä¸Šç¤ºç¯„ç¨‹å¼ç‰‡æ®µ
- çµå°¾ä»¥ã€Œä½ è¦ºå¾—å‘¢ï¼Ÿã€ã€ã€Œæ˜¯å¦èƒ½å»¶ä¼¸åˆ°â€¦ï¼Ÿã€æ”¶å°¾

è«‹ç”¨ 3â€“5 å¥å›ç­”ï¼Œæ¯å¥ä¸è¶…é 30 å­—ã€‚
{level_hint}
{code_hint}
ä¸»é¡Œï¼š{learning_unit}
å­¸ç”Ÿæå•ï¼š{user_message}
å›ç­”çµæŸæ™‚è¼¸å‡º [[END]]
""",
    }

    system_prompt = scaffolding_prompts.get(
        scaffolding_type, scaffolding_prompts["å·®ç•°é·¹æ¶"]
    )

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message},
            ],
            max_tokens=300,
            temperature=0.35,
            stop=["[[END]]"],
        )

        raw = response.choices[0].message.content
        processed = _postprocess_complete_sentences(raw)
        return format_code_blocks(processed)

    except Exception as e:
        print(f"å›æ‡‰ç”ŸæˆéŒ¯èª¤: {e}")
        return "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€è¡“å•é¡Œã€‚èƒ½è«‹ä½ å†èªªä¸€æ¬¡ä½ çš„å•é¡Œå—ï¼Ÿ"


# æ¨è–¦æ›¸ç± çˆ¬èŸ²
# é—œéµå­—æå–
def extract_keywords_from_message(user_message):
    """ä½¿ç”¨OpenAIæå–ç”¨æˆ¶è¨Šæ¯ä¸­çš„é—œéµè©"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€å€‹é—œéµè©æå–å°ˆå®¶ã€‚å¾ç”¨æˆ¶çš„è¨Šæ¯ä¸­æå–èˆ‡æ©Ÿå™¨å­¸ç¿’ã€è³‡æ–™ç§‘å­¸ã€ç¨‹å¼è¨­è¨ˆç›¸é—œçš„é—œéµè©ã€‚åªå›å‚³æœ€é‡è¦çš„1-2å€‹é—œéµè©ï¼Œç”¨é€—è™Ÿåˆ†éš”ã€‚å¦‚æœæ²’æœ‰ç›¸é—œé—œéµè©ï¼Œå›å‚³'æ©Ÿå™¨å­¸ç¿’'ã€‚",
                },
                {"role": "user", "content": f"è«‹å¾é€™æ®µè©±æå–é—œéµè©ï¼š{user_message}"},
            ],
            max_tokens=50,
            temperature=0.3,
        )
        keywords = response.choices[0].message.content.strip()
        return keywords
    except Exception as e:
        print(f"é—œéµè©æå–éŒ¯èª¤: {e}")
        return "æ©Ÿå™¨å­¸ç¿’"


# æ›¸ç±çˆ¬èŸ²
def search_books_google(keywords):
    """ä½¿ç”¨Googleæœç´¢ç›¸é—œæ›¸ç±"""
    # å°‡é—œéµå­—ç·¨ç¢¼ï¼Œçµ„æˆæœå°‹ URL
    url = f"https://search.books.com.tw/search/query/key/{quote(keywords)}/cat/all"
    print(url)
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36"
    }

    # ç™¼é€ GET è«‹æ±‚
    resp = requests.get(url, headers=headers, timeout=10)
    resp.raise_for_status()  # å¦‚æœæœ‰éŒ¯èª¤ç›´æ¥æ‹‹å‡º

    soup = BeautifulSoup(resp.text, "html.parser")
    # æ‰¾åˆ° table-td è£¡é¢çš„ <a> æ¨™ç±¤
    a_tag = soup.select_one(".table-td a")
    author = soup.select_one(".author a")
    img_tag = soup.select_one(".table-td img")
    if a_tag and a_tag.has_attr("title"):
        title_text = a_tag["title"]  # ç›´æ¥å– title å±¬æ€§
        href = a_tag["href"]
        if img_tag.has_attr("data-src"):  # æ‡¶åŠ è¼‰ç”¨ data-src
            img_src = img_tag["data-src"]
        else:  # ä¸€èˆ¬æƒ…æ³ç›´æ¥ src
            img_src = img_tag["src"]
    books = []
    books.append(
        {
            "title": title_text,
            "author": author.text,
            "image": img_src,
            "link": href,
            "source": "åšå®¢ä¾†",
        }
    )
    return books


# æŠ“å–æ›¸ç±çš„API
@app.route("/get_book_recommendations", methods=["POST"])
def get_book_recommendations():
    """ç²å–æ›¸ç±æ¨è–¦çš„APIç«¯é»"""
    if "username" not in session:
        return jsonify({"error": "æœªç™»å…¥"}), 401

    data = request.json
    user_message = data.get("message", "")

    if not user_message:
        return jsonify({"books": []})

    # æå–é—œéµè©
    keywords = extract_keywords_from_message(user_message)
    print(f"æå–çš„é—œéµè©: {keywords}")

    # æœç´¢ç›¸é—œæ›¸ç±
    books = search_books_google(keywords)

    return jsonify({"books": books, "keywords": keywords})


###########################################################################


###########################################################################  => teacher_analytics
# æ•™å¸«å„€è¡¨æ¿é é¢ é¿å…é€éæ›´æ”¹ç¶²å€é€²å…¥æ•™å¸«å¸³è™Ÿ
@app.route("/teacher")
def teacher_dashboard():
    if "username" not in session or session["username"] != "teacher":
        flash("ç„¡æ¬Šé™è¨ªå•", "alert alert-danger")
        return redirect(url_for("home"))
    return render_template("teacher_analytics.html", username=session["username"])


# æ•™å¸«åˆ†æAPI
@app.route("/teacher_analytics")
def teacher_analytics():
    if "username" not in session or session["username"] != "teacher":
        return jsonify({"error": "ç„¡æ¬Šé™"}), 403

    try:
        conn = sqlite3.connect(DB_NAME)
        c = conn.cursor()

        # æ´»èºå­¸ç”Ÿæ•¸ã€å¹³å‡ç†è§£ã€ç†±é–€å–®å…ƒã€å°è©±æ¬¡æ•¸
        stats = get_basic_stats(c)

        # é·¹æ¶é¡å‹çµ±è¨ˆ
        scaffolding_stats = get_scaffolding_stats(c)

        # å­¸ç¿’å–®å…ƒçµ±è¨ˆ
        unit_stats = get_unit_stats(c)

        # ç†è§£ç¨‹åº¦çµ±è¨ˆ
        level_stats = get_level_stats(c)

        # æ¯æ—¥æ´»å‹•çµ±è¨ˆ
        daily_activity = get_daily_activity(c)

        # æ¯å€‹å­¸ç”Ÿçš„ ç¸½å°è©±æ¬¡æ•¸ã€é·¹æ¶ã€ç†è§£ç¨‹åº¦ã€æœ€å¸¸è¨è«–å–®å…ƒã€ä¸Šæ¬¡ç™»å…¥æ™‚é–“
        students = get_student_details(c)

        conn.close()

        return jsonify(
            {
                "stats": stats,
                "scaffolding_stats": scaffolding_stats,
                "unit_stats": unit_stats,
                "level_stats": level_stats,
                "daily_activity": daily_activity,
                "students": students,
            }
        )

    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ç²å–å­¸ç”Ÿç›¸é—œè³‡æ–™
def get_basic_stats(cursor):
    """ç²å–åŸºæœ¬çµ±è¨ˆæ•¸æ“š"""
    # æ´»èºå­¸ç”Ÿæ•¸ï¼ˆéå»7å¤©ï¼‰
    week_ago = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d %H:%M:%S")
    cursor.execute(
        """
        SELECT COUNT(DISTINCT username) 
        FROM conversations 
        WHERE username != 'teacher' AND timestamp > ?
    """,
        (week_ago,),
    )
    # éå»7å¤©çš„å­¸ç”Ÿäººæ•¸
    active_students = cursor.fetchone()[0]

    # ç¸½å°è©±æ¬¡æ•¸
    cursor.execute("SELECT COUNT(*) FROM conversations WHERE username != 'teacher'")
    total_conversations = cursor.fetchone()[0]

    # æœ€ç†±é–€çš„å­¸ç¿’å–®å…ƒ æŒ‘å‡ºæ•¸é‡æœ€å¤šçš„å­¸ç¿’å–®å…ƒ
    cursor.execute(
        """
        SELECT learning_unit, COUNT(*) as count 
        FROM conversations 
        WHERE username != 'teacher' AND learning_unit IS NOT NULL 
        GROUP BY learning_unit 
        ORDER BY count DESC 
        LIMIT 1
    """
    )
    popular_result = cursor.fetchone()
    popular_unit = popular_result[0] if popular_result else "ç„¡"

    # å¹³å‡ç†è§£ç¨‹åº¦
    level_mapping = {"åˆå­¸è€…": 1, "é€²éšå­¸ç¿’è€…": 2, "ç†Ÿç·´è€…": 3}
    cursor.execute(
        """
        SELECT understanding_level 
        FROM conversations 
        WHERE username != 'teacher' AND understanding_level IS NOT NULL
    """
    )
    levels = [level_mapping.get(row[0], 0) for row in cursor.fetchall()]
    avg_level = round(sum(levels) / len(levels), 1) if levels else 0

    return {
        "activeStudents": active_students,
        "totalConversations": total_conversations,
        "popularUnit": popular_unit,
        "avgLevel": avg_level,
    }


def get_scaffolding_stats(cursor):
    """ç²å–é·¹æ¶é¡å‹çµ±è¨ˆ"""
    cursor.execute(
        """
        SELECT scaffolding_type, COUNT(*) as count 
        FROM conversations 
        WHERE username != 'teacher' AND scaffolding_type IS NOT NULL 
        GROUP BY scaffolding_type
    """
    )
    return dict(cursor.fetchall())


def get_unit_stats(cursor):
    """ç²å–å­¸ç¿’å–®å…ƒçµ±è¨ˆ"""
    cursor.execute(
        """
        SELECT learning_unit, COUNT(*) as count 
        FROM conversations 
        WHERE username != 'teacher' AND learning_unit IS NOT NULL 
        GROUP BY learning_unit 
        ORDER BY count DESC
    """
    )
    return dict(cursor.fetchall())


def get_level_stats(cursor):
    """ç²å–ç†è§£ç¨‹åº¦çµ±è¨ˆ"""
    cursor.execute(
        """
        SELECT understanding_level, COUNT(*) as count 
        FROM conversations 
        WHERE username != 'teacher' AND understanding_level IS NOT NULL 
        GROUP BY understanding_level
    """
    )
    return dict(cursor.fetchall())


def get_daily_activity(cursor):
    """ç²å–æ¯æ—¥æ´»å‹•çµ±è¨ˆï¼ˆéå»7å¤©ï¼‰"""
    daily_stats = {}
    for i in range(7):
        date = datetime.now() - timedelta(days=i)
        date_str = date.strftime("%Y-%m-%d")

        cursor.execute(
            """
            SELECT COUNT(*) 
            FROM conversations 
            WHERE username != 'teacher' 
            AND DATE(timestamp) = ?
        """,
            (date_str,),
        )

        count = cursor.fetchone()[0]
        daily_stats[date.strftime("%m/%d")] = (
            count  # daily_stats[9/15] = 4 => 9/15 æœ‰ 4å€‹äºº
        )

    # åè½‰é †åºï¼Œè®“æœ€èˆŠçš„æ—¥æœŸåœ¨å‰é¢
    return dict(reversed(list(daily_stats.items())))


def get_student_details(cursor):
    """ç²å–å­¸ç”Ÿè©³ç´°è³‡æ–™"""
    cursor.execute(
        "SELECT DISTINCT username FROM conversations WHERE username != 'teacher'"
    )
    usernames = [row[0] for row in cursor.fetchall()]

    students = []

    # æŠŠæ¯å€‹å­¸ç”ŸæŠ“å‡ºä¾†ï¼Œçœ‹ä»–çš„è³‡è¨Š
    for username in usernames:
        # ç¸½å°è©±æ¬¡æ•¸
        cursor.execute(
            "SELECT COUNT(*) FROM conversations WHERE username = ?", (username,)
        )
        total_conversations = cursor.fetchone()[0]

        # ä¸»è¦é·¹æ¶é¡å‹
        cursor.execute(
            """
            SELECT scaffolding_type, COUNT(*) as count 
            FROM conversations 
            WHERE username = ? AND scaffolding_type IS NOT NULL 
            GROUP BY scaffolding_type 
            ORDER BY count DESC 
            LIMIT 1
        """,
            (username,),
        )
        main_scaffolding_result = cursor.fetchone()
        main_scaffolding = (
            main_scaffolding_result[0] if main_scaffolding_result else "æœªçŸ¥"
        )

        # ç•¶å‰ç†è§£ç¨‹åº¦ï¼ˆæœ€æ–°çš„ï¼‰
        cursor.execute(
            """
            SELECT understanding_level 
            FROM conversations 
            WHERE username = ? AND understanding_level IS NOT NULL 
            ORDER BY timestamp DESC 
            LIMIT 1
        """,
            (username,),
        )
        current_level_result = cursor.fetchone()
        current_level = current_level_result[0] if current_level_result else "æœªçŸ¥"

        # æœ€å¸¸è¨è«–çš„å–®å…ƒ
        cursor.execute(
            """
            SELECT learning_unit, COUNT(*) as count 
            FROM conversations 
            WHERE username = ? AND learning_unit IS NOT NULL 
            GROUP BY learning_unit 
            ORDER BY count DESC 
            LIMIT 1
        """,
            (username,),
        )
        favorite_unit_result = cursor.fetchone()
        favorite_unit = favorite_unit_result[0] if favorite_unit_result else "ç„¡"

        # æœ€å¾Œæ´»å‹•æ™‚é–“
        cursor.execute(
            """
            SELECT MAX(timestamp) 
            FROM conversations 
            WHERE username = ?
        """,
            (username,),
        )
        last_activity = cursor.fetchone()[0]

        students.append(
            {
                "username": username,
                "total_conversations": total_conversations,
                "main_scaffolding": main_scaffolding,
                "current_level": current_level,
                "favorite_unit": favorite_unit,
                "last_activity": last_activity,
            }
        )

    # æŒ‰ç¸½å°è©±æ¬¡æ•¸æ’åº
    students.sort(key=lambda x: x["total_conversations"], reverse=True)
    return students


def get_user_learning_history(username):
    """ç²å–ä½¿ç”¨è€…çš„å­¸ç¿’æ­·å²è¨˜éŒ„"""
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    c.execute(
        """
        SELECT user_message, learning_unit, scaffolding_type, understanding_level 
        FROM conversations 
        WHERE username = ? 
        ORDER BY timestamp DESC 
        LIMIT 10
    """,
        (username,),
    )

    history = c.fetchall()
    conn.close()

    return history


import json
import re
from openai import OpenAI

client = OpenAI()


def normalize_scaffolding_type(scaffolding_type):
    """çµ±ä¸€é·¹æ¶é¡å‹åç¨±ï¼Œç§»é™¤æ‰€æœ‰ã€Œæ€§ã€å­—"""
    if not scaffolding_type:
        return "å·®ç•°é·¹æ¶"

    mapping = {
        "å·®ç•°æ€§é·¹æ¶": "å·®ç•°é·¹æ¶",
        "é‡è¤‡æ€§é·¹æ¶": "é‡è¤‡é·¹æ¶",
        "å”åŒæ€§é·¹æ¶": "å”åŒé·¹æ¶",
        "å·®ç•°é·¹æ¶": "å·®ç•°é·¹æ¶",
        "é‡è¤‡é·¹æ¶": "é‡è¤‡é·¹æ¶",
        "å”åŒé·¹æ¶": "å”åŒé·¹æ¶",
    }

    return mapping.get(scaffolding_type, "å·®ç•°é·¹æ¶")


# ä¿®æ”¹ analyze_scaffolding_need å‡½æ•¸
def analyze_scaffolding_need(user_message, learning_unit, user_history, username):
    """
    æ”¹è‰¯ç‰ˆï¼šä»¥é‡åŒ–å¹³å‡æ–¹å¼åˆ¤æ–·ç†è§£å±¤ç´šï¼ŒGPT ä¸»å°é·¹æ¶åˆ¤æ–·ã€‚
    """

    # === Step 1: æ ¹æ“šæ­·å²ç´€éŒ„é‡åŒ–ç†è§£å±¤ç´š ===
    level_score_map = {"åˆå­¸è€…": 1, "é€²éšå­¸ç¿’è€…": 2, "ç†Ÿç·´è€…": 3}

    valid_scores = [
        level_score_map[h[3]] for h in user_history if h[3] in level_score_map
    ]

    if valid_scores:
        avg_score = sum(valid_scores) / len(valid_scores)
    else:
        avg_score = 1

    if avg_score < 1.5:
        understanding_level = "åˆå­¸è€…"
    elif avg_score < 2.5:
        understanding_level = "é€²éšå­¸ç¿’è€…"
    else:
        understanding_level = "ç†Ÿç·´è€…"

    # === Step 2: è®“ GPT ä¸»å°åˆ¤æ–·é·¹æ¶é¡å‹ ===
    refinement_prompt = f"""
ä½ æ˜¯ä¸€ä½æ©Ÿå™¨å­¸ç¿’æ•™è‚²å°ˆå®¶ã€‚
æ ¹æ“šé·¹æ¶ç†è«–ï¼Œè«‹åˆ¤æ–·æ­¤å­¸ç”Ÿç›®å‰æœ€éœ€è¦çš„é·¹æ¶é¡å‹ã€‚

é·¹æ¶ç†è«–å®šç¾©å¦‚ä¸‹ï¼š
- å·®ç•°é·¹æ¶ï¼šç•¶å­¸ç”Ÿå°ç›¸åŒä¸»é¡Œç†è§£ç¨‹åº¦ä¸ä¸€ï¼Œæˆ–å­¸ç¿’é¢¨æ ¼ä¸åŒæ™‚ï¼Œæä¾›ä¸åŒè§’åº¦ã€é›£åº¦èˆ‡ç¯„ä¾‹å¼•å°ã€‚
- é‡è¤‡é·¹æ¶ï¼šç•¶å­¸ç”Ÿé‡å°ç‰¹å®šä¸»é¡Œéœ€è¦éå›ºç†è§£ï¼Œæä¾›å¤šå…ƒèªªæ˜æ–¹å¼æˆ–å¤šç¨®åšæ³•ï¼Œå”åŠ©åè¦†ç·´ç¿’ã€‚
- å”åŒé·¹æ¶ï¼šç•¶å­¸ç”Ÿè™•ç†éœ€è¦æ•´åˆå¤šé …çŸ¥è­˜èˆ‡æŠ€èƒ½çš„é«˜å±¤æ¬¡ä»»å‹™ï¼Œå”åŠ©æ•´åˆæ¦‚å¿µèˆ‡ç­–ç•¥ã€‚

å­¸ç”Ÿç›®å‰ç†è§£å±¤ç´šï¼š{understanding_level}
å­¸ç¿’å–®å…ƒï¼š{learning_unit}
å­¸ç”Ÿæå•ï¼š{user_message}

æ­·å²ç´€éŒ„æ‘˜è¦ï¼š
{[f"å•é¡Œï¼š{h[0]}ï¼Œå–®å…ƒï¼š{h[1]}ï¼Œç†è§£ï¼š{h[3]}" for h in user_history[-5:]]}

**é‡è¦ï¼šscaffolding_type å¿…é ˆåªèƒ½æ˜¯ä»¥ä¸‹ä¸‰å€‹å€¼ä¹‹ä¸€ï¼ˆä¸å¯åŠ ã€Œæ€§ã€å­—ï¼‰ï¼š**
- å·®ç•°é·¹æ¶
- é‡è¤‡é·¹æ¶
- å”åŒé·¹æ¶

å›å‚³ JSON æ ¼å¼ï¼ˆä¸è¦ä»»ä½• markdown èªæ³•ï¼‰ï¼š
{{
    "scaffolding_type": "å·®ç•°é·¹æ¶",
    "understanding_level": "åˆå­¸è€…",
    "reason": "ç°¡çŸ­èªªæ˜"
}}
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯æ•™è‚²å¿ƒç†å­¸åŠ©ç†ã€‚å›è¦†å¿…é ˆæ˜¯ç´” JSONï¼Œä¸è¦ä½¿ç”¨ markdownã€‚é·¹æ¶é¡å‹åªèƒ½æ˜¯ï¼šå·®ç•°é·¹æ¶ã€é‡è¤‡é·¹æ¶ã€å”åŒé·¹æ¶ï¼ˆä¸å¯åŠ æ€§å­—ï¼‰ã€‚",
                },
                {"role": "user", "content": refinement_prompt},
            ],
            max_tokens=250,
            temperature=0.2,
        )

        text = response.choices[0].message.content.strip()
        # ç§»é™¤å¯èƒ½çš„ markdown æ¨™è¨˜
        text = text.replace("```json", "").replace("```", "").strip()

        match = re.search(r"\{.*\}", text, re.DOTALL)
        if match:
            data = json.loads(match.group(0))
            scaffolding_type = normalize_scaffolding_type(
                data.get("scaffolding_type", "å·®ç•°é·¹æ¶")
            )
            understanding_level = data.get("understanding_level", understanding_level)
            reason = data.get("reason", "æ¨™æº–é·¹æ¶åˆ†æ")

            return scaffolding_type, understanding_level, reason
        else:
            print(f"ç„¡æ³•è§£æ GPT å› è¦†: {text}")
            return "å·®ç•°é·¹æ¶", understanding_level, "ç„¡æ³•è§£æ GPT å›è¦†ï¼Œä½¿ç”¨é è¨­çµæœã€‚"

    except Exception as e:
        print(f"é·¹æ¶åˆ†æéŒ¯èª¤: {e}")
        return "å·®ç•°é·¹æ¶", understanding_level, "åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚"


def analyze_scaffolding_need(user_message, learning_unit, user_history, username):
    """
    æ”¹è‰¯ç‰ˆï¼šä»¥é‡åŒ–å¹³å‡æ–¹å¼åˆ¤æ–·ç†è§£å±¤ç´šï¼ŒGPT ä¸»å°é·¹æ¶åˆ¤æ–·ã€‚
    """

    # === Step 1: æ ¹æ“šæ­·å²ç´€éŒ„é‡åŒ–ç†è§£å±¤ç´š ===
    level_score_map = {"åˆå­¸è€…": 1, "é€²éšå­¸ç¿’è€…": 2, "ç†Ÿç·´è€…": 3}

    # éæ¿¾æ‰æœªçŸ¥ç´€éŒ„ï¼Œæ›ç®—æˆåˆ†æ•¸
    valid_scores = [
        level_score_map[h[3]] for h in user_history if h[3] in level_score_map
    ]

    if valid_scores:
        avg_score = sum(valid_scores) / len(valid_scores)
    else:
        avg_score = 1  # è‹¥æ²’æœ‰ç´€éŒ„ï¼Œé è¨­åˆå­¸è€…

    # æ ¹æ“šå¹³å‡åˆ†æ•¸æ±ºå®šç›®å‰ç†è§£å±¤ç´š
    if avg_score < 1.5:
        understanding_level = "åˆå­¸è€…"
    elif avg_score < 2.5:
        understanding_level = "é€²éšå­¸ç¿’è€…"
    else:
        understanding_level = "ç†Ÿç·´è€…"

    # === Step 2: è®“ GPT ä¸»å°åˆ¤æ–·é·¹æ¶é¡å‹ ===
    refinement_prompt = f"""
    ä½ æ˜¯ä¸€ä½æ©Ÿå™¨å­¸ç¿’æ•™è‚²å°ˆå®¶ã€‚
    æ ¹æ“šé·¹æ¶ç†è«–ï¼Œè«‹åˆ¤æ–·æ­¤å­¸ç”Ÿç›®å‰æœ€éœ€è¦çš„é·¹æ¶é¡å‹ã€‚

    é·¹æ¶ç†è«–å®šç¾©å¦‚ä¸‹ï¼š
    - å·®ç•°é·¹æ¶ï¼šç•¶å­¸ç”Ÿå°ç›¸åŒä¸»é¡Œç†è§£ç¨‹åº¦ä¸ä¸€ï¼Œæˆ–å­¸ç¿’é¢¨æ ¼ä¸åŒæ™‚ï¼ŒChatGPT æ‡‰æä¾›ä¸åŒè§’åº¦ã€é›£åº¦èˆ‡ç¯„ä¾‹å¼•å°ã€‚
    - é‡è¤‡é·¹æ¶ï¼šç•¶å­¸ç”Ÿé‡å°ç‰¹å®šä¸»é¡Œéœ€è¦éå›ºç†è§£ï¼ŒChatGPT æ‡‰æä¾›å¤šå…ƒèªªæ˜æ–¹å¼æˆ–å¤šç¨®åšæ³•ï¼Œå”åŠ©åè¦†ç·´ç¿’ã€‚
    - å”åŒé·¹æ¶ï¼šç•¶å­¸ç”Ÿè™•ç†éœ€è¦æ•´åˆå¤šé …çŸ¥è­˜èˆ‡æŠ€èƒ½çš„é«˜å±¤æ¬¡ä»»å‹™ï¼ŒChatGPT æ‡‰å”åŠ©æ•´åˆæ¦‚å¿µèˆ‡ç­–ç•¥ï¼Œä¿ƒé€²æ•´é«”æ€è€ƒèˆ‡æ‡‰ç”¨ã€‚

    å­¸ç”Ÿç›®å‰ç†è§£å±¤ç´šï¼š{understanding_level}
    å­¸ç¿’å–®å…ƒï¼š{learning_unit}
    å­¸ç”Ÿæå•ï¼š{user_message}

    æ­·å²ç´€éŒ„æ‘˜è¦ï¼š
    {[f"å•é¡Œï¼š{h[0]}ï¼Œå–®å…ƒï¼š{h[1]}ï¼Œç†è§£ï¼š{h[3]}" for h in user_history[-5:]]}

    è«‹ä¾æ“šä»¥ä¸Šå…§å®¹åˆ¤æ–·ï¼š
    1. å­¸ç”Ÿæœ€é©åˆçš„é·¹æ¶é¡å‹ï¼ˆå¿…é ˆæ˜¯ä»¥ä¸‹ä¸‰ç¨®ä¹‹ä¸€ï¼šå·®ç•°é·¹æ¶ã€é‡è¤‡é·¹æ¶ã€å”åŒé·¹æ¶ï¼‰
    2. ç†ç”±ï¼ˆç°¡çŸ­èªªæ˜å­¸ç”Ÿç‚ºä½•éœ€è¦é€™é¡é·¹æ¶ï¼‰
    3. è‹¥æœ‰éœ€è¦ï¼Œå¯æ ¹æ“šå•é¡Œèªæ„èª¿æ•´ç†è§£å±¤ç´šã€‚

    é‡è¦ï¼šscaffolding_type å¿…é ˆå®Œå…¨ç¬¦åˆä»¥ä¸‹æ ¼å¼ï¼ˆä¸å¯æœ‰ä»»ä½•è®ŠåŒ–ï¼‰ï¼š
    - "å·®ç•°é·¹æ¶"
    - "é‡è¤‡é·¹æ¶"
    - "å”åŒé·¹æ¶"

    å›å‚³ JSON æ ¼å¼ï¼š
    {{
        "scaffolding_type": "å·®ç•°é·¹æ¶",
        "understanding_level": "åˆå­¸è€…",
        "reason": "ç°¡çŸ­ä¸­æ–‡èªªæ˜"
    }}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä½æ•™è‚²å¿ƒç†å­¸åŠ©ç†ã€‚è«‹åš´æ ¼éµå®ˆé·¹æ¶é¡å‹çš„å‘½åè¦ç¯„ã€‚",
                },
                {"role": "user", "content": refinement_prompt},
            ],
            max_tokens=250,
            temperature=0.3,
        )

        text = response.choices[0].message.content.strip()
        match = re.search(r"\{.*\}", text, re.DOTALL)
        if match:
            data = json.loads(match.group(0))
            scaffolding_type = data["scaffolding_type"]

            # ğŸ”¥ ä¿®æ­£ï¼šçµ±ä¸€é·¹æ¶é¡å‹åç¨±ï¼Œç§»é™¤ã€Œæ€§ã€å­—
            scaffolding_mapping = {
                "å·®ç•°æ€§é·¹æ¶": "å·®ç•°é·¹æ¶",
                "é‡è¤‡æ€§é·¹æ¶": "é‡è¤‡é·¹æ¶",
                "å”åŒæ€§é·¹æ¶": "å”åŒé·¹æ¶",
                "å·®ç•°é·¹æ¶": "å·®ç•°é·¹æ¶",
                "é‡è¤‡é·¹æ¶": "é‡è¤‡é·¹æ¶",
                "å”åŒé·¹æ¶": "å”åŒé·¹æ¶",
            }

            # å¦‚æœ GPT è¿”å›äº†å¸¶ã€Œæ€§ã€çš„ç‰ˆæœ¬ï¼Œè‡ªå‹•ä¿®æ­£
            scaffolding_type = scaffolding_mapping.get(scaffolding_type, "å·®ç•°é·¹æ¶")

            return scaffolding_type, data["understanding_level"], data["reason"]
        else:
            return (
                "å·®ç•°é·¹æ¶",
                understanding_level,
                "ç„¡æ³•è§£æ GPT å›è¦†ï¼Œä½¿ç”¨é è¨­çµæœã€‚",
            )

    except Exception as e:
        print(f"é·¹æ¶åˆ†æéŒ¯èª¤: {e}")
        return "å·®ç•°é·¹æ¶", understanding_level, "åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚"


###########################################################################


###########################################################################  => aiChatRobot
# AIèŠå¤©
@app.route("/dashboard")
def dashboard():
    if "username" not in session:
        return render_template("home.html")
    return render_template("aiChatRobot.html", username=session["username"])


###########################################################################


# å°è©±ç´€éŒ„
@app.route("/chat/history")
def chat_history():
    if "username" not in session:
        return jsonify({"error": "æœªç™»å…¥"}), 401

    username = session["username"]
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()
    c.execute(
        """
        SELECT user_message, bot_reply, learning_unit, scaffolding_type, understanding_level 
        FROM conversations 
        WHERE username = ? 
        ORDER BY timestamp ASC
    """,
        (username,),
    )
    rows = c.fetchall()
    conn.close()

    history = []
    for (
        user_msg,
        bot_reply,
        learning_unit,
        scaffolding_type,
        understanding_level,
    ) in rows:
        history.append({"role": "user", "content": user_msg})
        history.append(
            {
                "role": "ai",
                "content": bot_reply,
                "learning_unit": learning_unit,
                "scaffolding_type": scaffolding_type,
                "understanding_level": understanding_level,
            }
        )

    return jsonify(history)


# å€‹äººå­¸ç¿’åˆ†æé é¢
@app.route("/my_learning")
def my_learning():
    if "username" not in session:
        return redirect(url_for("home"))
    return render_template("my_learning.html", username=session["username"])


# å€‹äººå­¸ç¿’åˆ†æ API
@app.route("/my_learning_analytics")
def my_learning_analytics():
    if "username" not in session:
        return jsonify({"error": "æœªç™»å…¥"}), 401

    username = session["username"]

    try:
        conn = sqlite3.connect(DB_NAME)
        c = conn.cursor()

        # ç²å–ä½¿ç”¨è€…æ‰€æœ‰å°è©±è¨˜éŒ„
        c.execute(
            """
            SELECT learning_unit, understanding_level, user_message, scaffolding_type, timestamp
            FROM conversations 
            WHERE username = ? 
            ORDER BY timestamp DESC
        """,
            (username,),
        )
        conversations = c.fetchall()
        conn.close()

        if not conversations:
            return jsonify(
                {
                    "unit_progress": {},
                    "weakness_analysis": {},
                    "overall_stats": {
                        "total_conversations": 0,
                        "units_studied": 0,
                        "avg_level": "åˆå­¸è€…",
                        "most_discussed_unit": "ç„¡",
                    },
                    "scaffolding_stats": {},  # æ–°å¢é·¹æ¶çµ±è¨ˆ
                    "timeline": [],
                }
            )

        # åˆ†æå„å–®å…ƒçš„ç†è§£ç¨‹åº¦
        unit_progress = analyze_unit_progress(conversations)

        # åˆ†æå„å–®å…ƒçš„å¼±é»
        weakness_analysis = analyze_unit_weakness(conversations, username)

        # æ•´é«”çµ±è¨ˆ
        overall_stats = calculate_overall_stats(conversations)

        # é·¹æ¶é¡å‹çµ±è¨ˆ (æ–°å¢)
        scaffolding_stats = calculate_scaffolding_stats(conversations)

        # å­¸ç¿’æ™‚é–“è»¸
        timeline = generate_learning_timeline(conversations)

        return jsonify(
            {
                "unit_progress": unit_progress,
                "weakness_analysis": weakness_analysis,
                "overall_stats": overall_stats,
                "scaffolding_stats": scaffolding_stats,  # æ–°å¢
                "timeline": timeline,
            }
        )

    except Exception as e:
        print(f"å€‹äººåˆ†æéŒ¯èª¤: {e}")
        return jsonify({"error": str(e)}), 500


def calculate_scaffolding_stats(conversations):
    """è¨ˆç®—ä½¿ç”¨è€…çš„é·¹æ¶é¡å‹çµ±è¨ˆ"""
    scaffolding_counter = Counter()

    for unit, level, message, scaffolding, timestamp in conversations:
        if scaffolding:
            # ç¢ºä¿çµ±ä¸€æ ¼å¼
            scaffolding = normalize_scaffolding_type(scaffolding)
            scaffolding_counter[scaffolding] += 1

    # è¨ˆç®—ç™¾åˆ†æ¯”
    total = sum(scaffolding_counter.values())
    scaffolding_stats = {}

    if total > 0:
        for scaffolding_type, count in scaffolding_counter.items():
            scaffolding_stats[scaffolding_type] = {
                "count": count,
                "percentage": round((count / total) * 100, 1),
            }

    return scaffolding_stats


def calculate_overall_stats(conversations):
    """è¨ˆç®—æ•´é«”å­¸ç¿’çµ±è¨ˆ"""
    level_scores = {"åˆå­¸è€…": 1, "é€²éšå­¸ç¿’è€…": 2, "ç†Ÿç·´è€…": 3}

    units = set([c[0] for c in conversations if c[0] and c[0] != "é€šç”¨æ¦‚å¿µ"])
    levels = [level_scores.get(c[1], 0) for c in conversations if c[1]]

    avg_level_score = sum(levels) / len(levels) if levels else 0
    avg_level_name = get_level_name(round(avg_level_score))

    # æœ€å¸¸è¨è«–çš„å–®å…ƒ
    unit_counter = Counter([c[0] for c in conversations if c[0] and c[0] != "é€šç”¨æ¦‚å¿µ"])
    most_discussed = unit_counter.most_common(1)[0][0] if unit_counter else "ç„¡"

    # ä¸»è¦é·¹æ¶é¡å‹ (æ–°å¢)
    scaffolding_counter = Counter(
        [normalize_scaffolding_type(c[3]) for c in conversations if c[3]]
    )
    main_scaffolding = (
        scaffolding_counter.most_common(1)[0][0] if scaffolding_counter else "ç„¡"
    )

    return {
        "total_conversations": len(conversations),
        "units_studied": len(units),
        "avg_level": avg_level_name,
        "most_discussed_unit": most_discussed,
        "main_scaffolding": main_scaffolding,  # æ–°å¢
    }


def analyze_unit_progress(conversations):
    """åˆ†æå„å­¸ç¿’å–®å…ƒçš„ç†è§£ç¨‹åº¦é€²å±•"""
    unit_data = {}
    level_scores = {"åˆå­¸è€…": 1, "é€²éšå­¸ç¿’è€…": 2, "ç†Ÿç·´è€…": 3, "æœªçŸ¥": 0}

    for unit, level, _, scaffolding, timestamp in conversations:
        if not unit or unit == "é€šç”¨æ¦‚å¿µ":
            continue

        if unit not in unit_data:
            unit_data[unit] = {
                "conversations": 0,
                "levels": [],
                "scaffolding_types": [],
                "first_seen": timestamp,
                "last_seen": timestamp,
            }

        unit_data[unit]["conversations"] += 1
        unit_data[unit]["levels"].append(level_scores.get(level, 0))
        unit_data[unit]["scaffolding_types"].append(scaffolding)
        unit_data[unit]["last_seen"] = timestamp

    # è¨ˆç®—å„å–®å…ƒçš„å¹³å‡ç†è§£ç¨‹åº¦å’Œé€²æ­¥è¶¨å‹¢
    result = {}
    for unit, data in unit_data.items():
        avg_level = sum(data["levels"]) / len(data["levels"]) if data["levels"] else 0

        # è¨ˆç®—é€²æ­¥è¶¨å‹¢ï¼ˆæœ€è¿‘3æ¬¡ vs æœ€æ—©3æ¬¡ï¼‰
        recent_levels = data["levels"][: min(3, len(data["levels"]))]
        early_levels = data["levels"][-min(3, len(data["levels"])) :]

        trend = "æŒå¹³"
        if len(data["levels"]) >= 3:
            recent_avg = sum(recent_levels) / len(recent_levels)
            early_avg = sum(early_levels) / len(early_levels)

            if recent_avg > early_avg + 0.3:
                trend = "é€²æ­¥ä¸­"
            elif recent_avg < early_avg - 0.3:
                trend = "éœ€åŠ å¼·"

        # æœ€å¸¸ä½¿ç”¨çš„é·¹æ¶é¡å‹
        scaffolding_counter = Counter([s for s in data["scaffolding_types"] if s])
        most_common_scaffolding = (
            scaffolding_counter.most_common(1)[0][0] if scaffolding_counter else "æœªçŸ¥"
        )

        result[unit] = {
            "conversations": data["conversations"],
            "avg_level": round(avg_level, 2),
            "current_level": (
                get_level_name(data["levels"][0]) if data["levels"] else "æœªçŸ¥"
            ),
            "trend": trend,
            "most_scaffolding": most_common_scaffolding,
            "last_studied": data["last_seen"],
        }

    return result


def analyze_unit_weakness(conversations, username):
    """ä½¿ç”¨ GPT åˆ†æå„å–®å…ƒçš„å¼±é»"""
    unit_conversations = {}

    # æŒ‰å–®å…ƒåˆ†çµ„å°è©±
    for unit, level, message, scaffolding, timestamp in conversations:
        if not unit or unit == "é€šç”¨æ¦‚å¿µ":
            continue

        if unit not in unit_conversations:
            unit_conversations[unit] = []

        unit_conversations[unit].append(
            {"message": message, "level": level, "scaffolding": scaffolding}
        )

    weakness_result = {}

    for unit, convs in unit_conversations.items():
        # åªåˆ†ææœ‰è¶³å¤ å°è©±è¨˜éŒ„çš„å–®å…ƒï¼ˆè‡³å°‘3æ¬¡å°è©±ï¼‰
        if len(convs) < 3:
            weakness_result[unit] = {
                "weakness": "å°è©±æ¬¡æ•¸ä¸è¶³ï¼Œå°šç„¡æ³•åˆ†æå¼±é»",
                "suggestions": ["å»ºè­°å¤šèˆ‡ AI è¨è«–æ­¤å–®å…ƒçš„å…§å®¹"],
                "confidence": "ä½",
            }
            continue

        # å–æœ€è¿‘5æ¬¡å°è©±é€²è¡Œåˆ†æ
        recent_convs = convs[:5]

        # æ§‹å»º GPT åˆ†ææç¤º
        analysis_prompt = f"""
ä½ æ˜¯ä¸€ä½æ©Ÿå™¨å­¸ç¿’æ•™è‚²å°ˆå®¶ã€‚è«‹æ ¹æ“šå­¸ç”Ÿåœ¨ã€Œ{unit}ã€å–®å…ƒçš„å­¸ç¿’è¨˜éŒ„ï¼Œåˆ†æå…¶å¯èƒ½çš„å¼±é»ã€‚

å­¸ç¿’è¨˜éŒ„ï¼š
{chr(10).join([f"- å•é¡Œï¼š{c['message']} (ç†è§£ç¨‹åº¦ï¼š{c['level']}ï¼Œé·¹æ¶ï¼š{c['scaffolding']})" for c in recent_convs])}

è«‹åˆ†æï¼š
1. å­¸ç”Ÿåœ¨æ­¤å–®å…ƒæœ€ä¸»è¦çš„å¼±é»æˆ–å›°é›£ï¼ˆ1-2å¥è©±ï¼‰
2. 3å€‹å…·é«”çš„æ”¹å–„å»ºè­°
3. å¼±é»åˆ†æçš„ä¿¡å¿ƒç¨‹åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰

å›å‚³ JSON æ ¼å¼ï¼š
{{
    "weakness": "ä¸»è¦å¼±é»æè¿°",
    "suggestions": ["å»ºè­°1", "å»ºè­°2", "å»ºè­°3"],
    "confidence": "é«˜/ä¸­/ä½"
}}
"""

        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯æ•™è‚²åˆ†æå°ˆå®¶ï¼Œå°ˆé–€åˆ†æå­¸ç”Ÿçš„å­¸ç¿’å¼±é»ã€‚",
                    },
                    {"role": "user", "content": analysis_prompt},
                ],
                max_tokens=300,
                temperature=0.3,
            )

            result_text = response.choices[0].message.content.strip()

            # è§£æ JSON
            import re

            match = re.search(r"\{.*\}", result_text, re.DOTALL)
            if match:
                analysis = json.loads(match.group(0))
                weakness_result[unit] = analysis
            else:
                weakness_result[unit] = {
                    "weakness": "åˆ†æå¤±æ•—",
                    "suggestions": ["è«‹ç¹¼çºŒå­¸ç¿’"],
                    "confidence": "ä½",
                }

        except Exception as e:
            print(f"å–®å…ƒ {unit} å¼±é»åˆ†æéŒ¯èª¤: {e}")
            weakness_result[unit] = {
                "weakness": "ç³»çµ±åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤",
                "suggestions": ["è«‹ç¨å¾Œå†è©¦"],
                "confidence": "ä½",
            }

    return weakness_result


def calculate_overall_stats(conversations):
    """è¨ˆç®—æ•´é«”å­¸ç¿’çµ±è¨ˆ"""
    level_scores = {"åˆå­¸è€…": 1, "é€²éšå­¸ç¿’è€…": 2, "ç†Ÿç·´è€…": 3}

    units = set([c[0] for c in conversations if c[0] and c[0] != "é€šç”¨æ¦‚å¿µ"])
    levels = [level_scores.get(c[1], 0) for c in conversations if c[1]]

    avg_level_score = sum(levels) / len(levels) if levels else 0
    avg_level_name = get_level_name(round(avg_level_score))

    # æœ€å¸¸è¨è«–çš„å–®å…ƒ
    unit_counter = Counter([c[0] for c in conversations if c[0] and c[0] != "é€šç”¨æ¦‚å¿µ"])
    most_discussed = unit_counter.most_common(1)[0][0] if unit_counter else "ç„¡"

    return {
        "total_conversations": len(conversations),
        "units_studied": len(units),
        "avg_level": avg_level_name,
        "most_discussed_unit": most_discussed,
    }


def generate_learning_timeline(conversations):
    """ç”Ÿæˆå­¸ç¿’æ™‚é–“è»¸ï¼ˆæœ€è¿‘10æ¬¡é‡è¦å­¸ç¿’äº‹ä»¶ï¼‰"""
    timeline = []

    # ç¯©é¸å‡ºæœ‰æ˜ç¢ºå­¸ç¿’å–®å…ƒçš„å°è©±
    filtered = [
        (c[0], c[1], c[4]) for c in conversations if c[0] and c[0] != "é€šç”¨æ¦‚å¿µ"
    ]

    # å–æœ€è¿‘10æ¬¡
    for unit, level, timestamp in filtered[:10]:
        timeline.append({"unit": unit, "level": level, "timestamp": timestamp})

    return timeline


def get_level_name(score):
    """æ ¹æ“šåˆ†æ•¸è¿”å›ç†è§£ç¨‹åº¦åç¨±"""
    if score >= 2.5:
        return "ç†Ÿç·´è€…"
    elif score >= 1.5:
        return "é€²éšå­¸ç¿’è€…"
    else:
        return "åˆå­¸è€…"


# æ¸…é™¤å°è©±ç´€éŒ„
@app.route("/chat/clear", methods=["POST"])
def clear_chat():
    if "username" not in session:
        return jsonify({"error": "æœªç™»å…¥"}), 401

    username = session["username"]
    conn = sqlite3.connect(DB_NAME)
    c = conn.cursor()

    c.execute(
        """UPDATE conversations 
           SET user_message = '[å·²æ¸…é™¤]', bot_reply = '[å·²æ¸…é™¤]' 
           WHERE username = ?""",
        (username,),
    )

    conn.commit()
    conn.close()

    return jsonify({"success": True})


if __name__ == "__main__":
    init_db()
    app.run(debug=True)
